---
layout:     post
title:      深度学习入门学习笔记（四）
subtitle:   神经网络如何进行学习，如何确定权重参数
date:       2020-02-28
author:     aK
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Python
    - Neural Networks
    - fitting
---

>深度学习入门学习笔记（四）


# 第四章 神经网络的学习

本章导入损失函数这一指标，找到使损失函数最低的神经网络权重参数值

## 4.1 从数据中学习

在实际的神经网络中，权重参数极多，人工决定这些参数的值是不现实的，因次需要通过学习数据来推出这些权重参数的值。

机器学习中，一般将数据分为 **训练数据** 和 **测试数据** 两部分，训练数据也可被成为 **监督数据** 。

**泛化能力** 是指处理未被观察过的数据（不包含在训练数据中的数据）。 **获得泛化能力** 是机器学习的最终目标。

仅仅用一个数据集去学习和评价权重参数，是无法正确评价，会导致可以顺利的处理某个数据集，而无法处理其他数据集。

只对某个数据集拟合度极高的状态称为 **过拟合（over fitting）** 。避免过拟合也是机器学习的重要课题。



## 4.2 损失函数

神经网络的学习通过某个指标表示现在的状态。然后，以这个指标为基准，寻找最优权重参数。神经网络的学习使用的指标为 **损失函数（loss function）** 。这个损失函数一般使用均方误差和交叉熵误差。

* 均方误差

均方误差在python的表示为：

	def mean_squared_error(y, t):
        return 0.5 * np.sum((y-t)**2)

* 交叉熵误差

交叉熵误差在python的表示为：

	def cross_entropy_error(y, t):
        delta=1e-7
	    return -np.sum(t*np.lpg(y+delta))

交叉熵函数实质上是正确解标签的输出概率的自然对数。也就是说，交叉熵误差的值是由正确解标签所对应的输出概率决定的。

对应的mini-batch的交叉熵误差(标签为独热数据)再python中的表示为：

	def cross_entropy_error(y, t):
        if y.ndim == 1:
            t = t.reshape(1, t.size)
            y = y.reshape(1, y.size)
        
        # 监督数据是one-hot-vector的情况下，转换为正确解标签的索引
        if t.size == y.size:
            t = t.argmax(axis=1)
             
        batch_size = y.shape[0]
        return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size

**损失函数的意义** 是在寻找最优参数（权重和偏置）时，要寻找使损失函数最小的参数。为了找到使损失函数最小的参数，需要引入损失函数关于参数的导数（梯度），然后以导数为指引，逐步更新参数的值。

>在神经网络进行学习时，不能将识别精度作为指标，因为如果以识别精度作为指标，则参数的导数在绝大多数的地方都会变为0.





## 4.3 数值微分

数值微分定义及导数定义见高等数学




## 4.4 梯度

梯度定义见高等数学。

其定义在python中的表达为：

	def numerical_gradient(f, x):
    	h = 1e-4 # 0.0001
    	grad = np.zeros_like(x)
    
    	it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    	while not it.finished:
        	idx = it.multi_index
        	tmp_val = x[idx]
        	x[idx] = float(tmp_val) + h
        	fxh1 = f(x) # f(x+h)
        
       		x[idx] = tmp_val - h 
        	fxh2 = f(x) # f(x-h)
        	grad[idx] = (fxh1 - fxh2) / (2*h)
        
        	x[idx] = tmp_val # 还原值
        	it.iternext()   
        
    	return grad   

**梯度法（gradient methend）** ：函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的位置重新求取梯度，再沿着新的梯度方向前进，如此反复，不断沿着新梯度的方向前进，这种通过沿梯度前进从而减小函数值的方法就是梯度法。

梯度法时解决机器学习中最优化问题的常见方法，特别是在神经网络的学习中经常被用到。

在python中实现梯度法的表达为：

	def gradient_descent(f, init_x, lr=0.01, step_num=100):
    	x = init_x
    	x_history = []

    	for i in range(step_num):
       		x_history.append( x.copy() )

        	grad = numerical_gradient(f, x)
        	x -= lr * grad

    	return x, np.array(x_history)






## 4.5 学习算法的实现

神经网络的基础知识即位上述内容。通过损失函数、mini-batch、梯度、梯度下降法等内容，即可实现神经网络的学习。神经网络的学习步骤如下：

**步骤1 mini-batch**

从训练数据中随机挑选一部分数据，这部分数据称为mini-batch。我们的目标是减少mini-batch的损失函数的值

**步骤2 计算梯度**

为了减小mini-batch的损失函数值，需要求出各个权重参数的梯度，梯度表示损失函数的值减小最多的方向。


**步骤3 更新权重**

将权重参数沿梯度最小的方向进行微小更新。

**步骤4 重复步骤1-3**

### 4.5.1 2层神经网络的类

按照上述4步，实现一个2层的神经网络，源代码见下：


	# coding: utf-8
	import sys, os
	sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定
	from common.functions import *
	from common.gradient import numerical_gradient


	class TwoLayerNet:
	"""输入依次为：输入层的神经元数、隐藏层神经元数、输出层神经元数"""

    	def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        	# 初始化权重
        	self.params = {} #保存权重和偏置的字典
        	self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)#高斯分布随机数
        	self.params['b1'] = np.zeros(hidden_size)
        	self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)#高斯分布随机数
        	self.params['b2'] = np.zeros(output_size)

    	def predict(self, x):
       		W1, W2 = self.params['W1'], self.params['W2']#权重
        	b1, b2 = self.params['b1'], self.params['b2']#偏置
    
        	a1 = np.dot(x, W1) + b1#输入与权重点成，加偏置
        	z1 = sigmoid(a1)#激活函数
        	a2 = np.dot(z1, W2) + b2#输入与权重点成，加偏置
        	y = softmax(a2)#输出转换概率
        
        	return y
        
    	# x:输入数据, t:监督数据
    	def loss(self, x, t):
        	y = self.predict(x)
        
        	return cross_entropy_error(y, t)
    
    	def accuracy(self, x, t):
        	y = self.predict(x)
        	y = np.argmax(y, axis=1)
        	t = np.argmax(t, axis=1)
        
        	accuracy = np.sum(y == t) / float(x.shape[0])
        	return accuracy
        
    	# x:输入数据, t:监督数据
    	def numerical_gradient_intw(self, x, t):#与原书中不同，为了与gradient中的numerical_gradient方法显示区别，改名为numerical_gradient_intw
		#依据梯度定义计算梯度
        	loss_W = lambda W: self.loss(x, t)#匿名函数，无关输入，输入任意w，输出都是loss(x, t)（计算损失函数的值）
        
        	grads = {} #保存梯度的字典
        	grads['W1'] = numerical_gradient(loss_W, self.params['W1']) #此处是使用gradient中的函数，而非引用自身。
        	grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        	grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        	grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        
        	return grads
        
    	def gradient(self, x, t):
		#反向传播计算梯度，在第五章中介绍
        	W1, W2 = self.params['W1'], self.params['W2']
        	b1, b2 = self.params['b1'], self.params['b2']
        	grads = {}
        
        	batch_num = x.shape[0]
        
        	# forward
        	a1 = np.dot(x, W1) + b1
        	z1 = sigmoid(a1)
        	a2 = np.dot(z1, W2) + b2
        	y = softmax(a2)
        
        	# backward
        	dy = (y - t) / batch_num
        	grads['W2'] = np.dot(z1.T, dy)
        	grads['b2'] = np.sum(dy, axis=0)
        
        	da1 = np.dot(dy, W2.T)
        	dz1 = sigmoid_grad(a1) * da1
        	grads['W1'] = np.dot(x.T, dz1)
        	grads['b1'] = np.sum(dz1, axis=0)

        	return grads










神经网络的学习是使用mini-batch法。以TwoLayerNet类为对象，使用mnist数据集进行学习：



	# coding: utf-8
	import sys, os
	sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定
	import numpy as np
	import matplotlib.pyplot as plt
	from dataset.mnist import load_mnist
	from two_layer_net import TwoLayerNet

	# 读入数据
	(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)

	network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)

	iters_num = 10000  # 适当设定循环的次数
	train_size = x_train.shape[0]
	batch_size = 100
	learning_rate = 0.1

	train_loss_list = []
	train_acc_list = []
	test_acc_list = []
	#平均每个epoch的重复次数
	iter_per_epoch = max(train_size / batch_size, 1)

	for i in range(iters_num):
    	batch_mask = np.random.choice(train_size, batch_size)
    	x_batch = x_train[batch_mask]
    	t_batch = t_train[batch_mask]
    
    	# 计算梯度
    	#grad = network.numerical_gradient_intw(x_batch, t_batch)#指的是two_lawyer_net中的方法
    	grad = network.gradient(x_batch, t_batch)
    
    	# 更新参数
    	for key in ('W1', 'b1', 'W2', 'b2'):
        	network.params[key] -= learning_rate * grad[key]
    
    	loss = network.loss(x_batch, t_batch)
    	train_loss_list.append(loss)
    
    	if i % iter_per_epoch == 0:
        	train_acc = network.accuracy(x_train, t_train)
        	test_acc = network.accuracy(x_test, t_test)
        	train_acc_list.append(train_acc)
        	test_acc_list.append(test_acc)
        	print("train acc, test acc | " + str(train_acc) + ", " + str(test_acc))

	# 绘制图形
	markers = {'train': 'o', 'test': 's'}
	x = np.arange(len(train_acc_list))
	plt.plot(x, train_acc_list, label='train acc')
	plt.plot(x, test_acc_list, label='test acc', linestyle='--')
	plt.xlabel("epochs")
	plt.ylabel("accuracy")
	plt.ylim(0, 1.0)
	plt.legend(loc='lower right')
	plt.show()







